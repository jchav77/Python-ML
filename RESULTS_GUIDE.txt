"""
RESULTS INTERPRETATION GUIDE
============================

This guide helps you understand and interpret your analysis results.

TABLE OF CONTENTS
-----------------
1. Understanding Clustering Results
2. Interpreting Significance Tests
3. Common Patterns and What They Mean
4. Troubleshooting Guide
5. Next Steps and Recommendations

================================================================================
1. UNDERSTANDING CLUSTERING RESULTS
================================================================================

WHERE TO FIND RESULTS:
- output/03_cluster_profiles_[target].csv - Summary statistics per cluster
- output/03_clustered_[target].csv - Full data with cluster assignments
- output/figures/03_elbow_[target].png - Elbow method visualization
- output/figures/03_silhouette_[target].png - Silhouette score visualization

WHAT TO LOOK FOR:

A. Optimal Number of Clusters
   - ELBOW PLOT: Look for where the line "bends" (elbow point)
     • Before elbow: Each new cluster adds substantial value
     • After elbow: Diminishing returns - new clusters don't help much
   
   - SILHOUETTE PLOT: Higher scores = better cluster separation
     • Score > 0.7: Strong, well-separated clusters (excellent!)
     • Score 0.5-0.7: Reasonable cluster structure (good)
     • Score < 0.5: Weak cluster structure (may want to reconsider)
   
   EXAMPLE INTERPRETATION:
   "Elbow is at K=5, and K=5 also has the highest silhouette score (0.63).
    This suggests 5 distinct customer segments."

B. Cluster Profiles
   Look at the cluster_profiles CSV:
   
   Column: target_mean
   - This is the average outcome for customers in that cluster
   - Compare across clusters: Which clusters perform best/worst?
   
   Column: target_count  
   - How many customers are in each cluster
   - Very small clusters (<5% of total) might not be actionable
   
   EXAMPLE INTERPRETATION:
   "Cluster 2 has the highest recovery rate (18.5%) with 2,400 customers.
    Cluster 4 has the lowest (8.2%) with 1,100 customers."

C. Cluster Characteristics
   Look at the distinctive features printed in terminal output:
   
   These show which features are most common (>50%) in each cluster.
   
   EXAMPLE:
   Cluster 2:
   • collateral_status_collateral: 95%
   • last_rpc_months_0-1: 78%
   • balance_bin_5000+: 82%
   
   INTERPRETATION:
   "Cluster 2 is primarily collateral accounts with high balances who were
    recently contacted. These are your best-performing customers."

================================================================================
2. INTERPRETING SIGNIFICANCE TESTS
================================================================================

WHERE TO FIND RESULTS:
- output/04_significance_results_[target].csv - All test results
- output/04_significant_clusters_[target].csv - Only significant results
- output/figures/04_significance_[target].png - Visual summary

KEY METRICS:

A. P-value
   "What's the probability this difference is just random chance?"
   
   • p < 0.10: 90% confident the difference is real (marked with *)
   • p < 0.05: 95% confident (marked with **)
   • p < 0.01: 99% confident (marked with ***)
   • p ≥ 0.10: Not confident - could be random
   
   LOWER p-values = STRONGER evidence

B. Difference (or difference_pct for proportions)
   "How big is the effect?"
   
   For PROPORTIONS (RPC, payment flags):
   • difference_pct = test% - control%
   • Example: +5.2 percentage points means test group had 5.2% higher rate
   
   For CONTINUOUS (recovery percent):
   • difference = test_mean - control_mean  
   • Example: +2.3 means test group had 2.3 percentage points higher recovery
   
   POSITIVE values = test performed better
   NEGATIVE values = control performed better

C. Confidence Intervals (ci_lower, ci_upper)
   "Range where we think the true difference lies"
   
   • If interval includes 0: The difference might be 0 (not significant)
   • If interval doesn't include 0: We're confident there's a real difference
   
   EXAMPLE:
   ci_lower = 1.2, ci_upper = 4.8
   INTERPRETATION: "We're 90% confident the true difference is between 
                    +1.2 and +4.8 percentage points"

D. Sample Sizes (n_test, n_control)
   • Larger samples = more reliable results
   • Small samples might not meet testing requirements
   
   MINIMUM REQUIREMENTS:
   - Proportions: ≥10 successes AND ≥10 failures in each group
   - Continuous: ≥10 in each group (preferably ≥30)

REAL-WORLD EXAMPLE:

Cluster 3 Results (RPC flag):
- test_proportion: 0.325 (32.5%)
- control_proportion: 0.278 (27.8%)
- difference_pct: +4.7 percentage points
- p_value: 0.032
- is_significant: YES
- n_test: 850, n_control: 420

INTERPRETATION:
"In Cluster 3, customers who received the campaign had a 32.5% RPC rate 
 compared to 27.8% for the control group - a difference of 4.7 percentage 
 points. With p=0.032, we're 95% confident this difference is real (not 
 random chance). This cluster had adequate sample sizes (850 test, 420 
 control) for reliable testing."

================================================================================
3. COMMON PATTERNS AND WHAT THEY MEAN
================================================================================

PATTERN 1: Most clusters show no significance
POSSIBLE CAUSES:
✗ Campaign had no real effect overall
✗ Sample sizes too small (especially in control group)
✗ Features don't predict response to campaign
✓ This is actually normal! Most campaigns don't work universally

ACTION: Focus on the few significant clusters - these are your insights!

PATTERN 2: One huge cluster, several tiny ones
POSSIBLE CAUSES:
✗ Features are too similar (not enough variation)
✗ One segment dominates your population
✗ K is set too high

ACTION: 
- Review feature selection - are they actually different?
- Consider using fewer clusters (lower K)
- Accept that one segment is just very common

PATTERN 3: Significant but small effects
EXAMPLE: +1.2 percentage points, p=0.03

INTERPRETATION: Statistically significant ≠ practically meaningful
- The effect is real (not random)
- But it might be too small to matter for business decisions

ACTION: Consider cost/benefit:
- If sending a letter costs $1 and the lift is minimal, maybe skip it
- If it's a free email and you gain 1% lift, maybe worth it

PATTERN 4: Large effects but not significant
EXAMPLE: +8.5 percentage points, p=0.15

POSSIBLE CAUSES:
✗ Sample size too small (especially common issue)
✗ High variation within groups

ACTION:
- Note these as "promising but needs more data"
- In next campaign, increase sample size for these segments
- Don't completely ignore them

PATTERN 5: Control group outperforms test
EXAMPLE: difference_pct = -3.2, p=0.04

INTERPRETATION: Campaign actually hurt performance!

POSSIBLE CAUSES:
- Survey fatigue (too many communications)
- Wrong message for this segment
- Bad timing

ACTION: Definitely exclude this segment from future campaigns!

================================================================================
4. TROUBLESHOOTING GUIDE
================================================================================

ERROR: "ModuleNotFoundError: No module named 'pandas'"
SOLUTION: Install required packages
   pip install -r requirements.txt

ERROR: "FileNotFoundError: [Errno 2] No such file or directory"
SOLUTION: Check file paths
   - Make sure your Excel file is in the data/ folder
   - Run scripts from the project root directory
   - Don't run from inside the scripts/ folder

ERROR: "ValueError: Input contains NaN"
SOLUTION: Missing values in data
   - Review output from 01_data_loading.py
   - Choose appropriate handling strategy in 02_preprocessing.py
   - Options: drop rows, fill with mode/median

ERROR: All clusters fail sample size requirements
SOLUTION: Not enough data in segments
   - Use fewer clusters (lower K)
   - Combine some features (reduce one-hot encoded columns)
   - Accept that only some clusters are testable

WARNING: Silhouette score < 0.5
INTERPRETATION: Weak cluster separation
SOLUTION:
   - Review feature selection
   - Try different values of K
   - Consider that your features might not naturally segment
   - This doesn't mean analysis failed - proceed and interpret cautiously

ISSUE: Python is very slow
CAUSES: Large dataset, too many features, high K
SOLUTION:
   - Reduce max_k in clustering (try max_k=10 instead of 15)
   - Sample your data for initial exploration
   - Close other programs
   - Reduce n_init in KMeans (try n_init=5 instead of 10)

ISSUE: Results don't make business sense
EXAMPLE: "NSOL accounts performing worse makes no sense!"
SOLUTION: Double-check your understanding
   - Verify column definitions
   - Check for data quality issues
   - Review feature encoding
   - Sometimes counterintuitive results are real insights!

================================================================================
5. NEXT STEPS AND RECOMMENDATIONS
================================================================================

AFTER RUNNING THE ANALYSIS:

STEP 1: Create Executive Summary
   - How many clusters found? (from clustering analysis)
   - How many showed significance? (from significance testing)
   - What's the pattern? (positive effects, negative effects, no effect)

STEP 2: Profile Significant Clusters
   For each significant cluster:
   a. Describe who they are (features)
   b. How they performed (effect size)
   c. How confident we are (p-value)
   d. How many customers (sample size)

STEP 3: Generate Recommendations
   Based on results:
   
   IF significant positive effect:
   → "Increase communication to this segment"
   
   IF significant negative effect:
   → "Exclude this segment from future campaigns"
   
   IF no significant effect:
   → "Current approach is fine, no changes needed"

STEP 4: Plan Next Campaign
   - Which segments to target
   - Which to exclude
   - What sample sizes needed for better testing

SAMPLE EXECUTIVE SUMMARY TEMPLATE:
-----------------------------------
Campaign Analysis Summary - [Date]

OVERVIEW:
- Analyzed 80,000 customers across [X] target metrics
- Identified [Y] natural customer segments through clustering
- Found [Z] segments with statistically significant results

KEY FINDINGS:

1. High-Value Collateral Accounts (Cluster 2)
   - Profile: Collateral accounts, balance >$5K, recent contact
   - Result: +6.2 percentage points in RPC rate (p=0.008)
   - Recommendation: Prioritize these accounts in future campaigns
   - Impact: 2,400 customers

2. [Additional findings...]

RECOMMENDATIONS:
- [Specific actions based on findings]

NEXT CAMPAIGN CONSIDERATIONS:
- [Adjustments to make]

================================================================================
FINAL TIPS
================================================================================

✓ Always review plots before accepting algorithm's optimal K
✓ Statistical significance ≠ practical significance
✓ Negative results (no effect) are still valuable insights
✓ Document your decisions and rationale
✓ Keep original data and all output files for reference
✓ Share significant findings with stakeholders early
✓ Don't over-interpret small samples or weak significance
✓ Remember: The goal is actionable insights, not perfect models

Questions? Review the code comments or consult a statistician for complex cases.
"""
